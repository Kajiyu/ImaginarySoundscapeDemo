# ImaginarySoundscape Demo

## Overview
- This is the demo repository of our project, "Imaginary Soundscape".
- At the original website, you can freely walk around Google Street View and immerse themselves into imaginary soundscape generated with deep learning models, but at this repository you can try the process to estimate the best sound from an image data.
- Our model is based on [SoundNet](), proposed in 2016.
- Our code is written at Python3 and Keras.

## References
- [Imaginary Soundscape](http://imaginarysoundscape.qosmo.jp/)
- [Another demo of Imaginary Soundscape](http://imaginarysoundscape2.qosmo.jp/)
- [Short paper at NIPS2017 Workshop](https://nips2017creativity.github.io/doc/Imaginary_Soundscape.pdf)


## Prerequisites
- Python 3
- Tensorflow
- Keras
- Linux or MacOSX

## Credits
- Concept/Machine Learning/Music: Nao Tokui
- Machine Learning: Yuma Kajihara
- UI Design/Programming: Shoya Dozono
