# ImaginarySoundscape Demo

## Overview
- This is the demo repository of our project, "[Imaginary Soundscape](http://imaginarysoundscape.qosmo.jp/)".
- At the original website, you can freely walk around Google Street View, but at this repository you can try the process to estimate the best sound from an image data.
- Our model is based on [SoundNet](http://soundnet.csail.mit.edu/), proposed in 2016.
- Our code is written at Python3 and Keras.

## How to use
1. Please download [this file](https://github.com/Kajiyu/ImaginarySoundscapeDemo/releases/download/v1.0.0/data.zip) and unzip into the current directory.
2. You can easily try with Jupyter Notebook. Please open `playground.ipynb`

## References
- [Imaginary Soundscape](http://imaginarysoundscape.qosmo.jp/)
- [Another demo of Imaginary Soundscape](http://imaginarysoundscape2.qosmo.jp/)
- [Short paper at NIPS2017 Workshop](https://nips2017creativity.github.io/doc/Imaginary_Soundscape.pdf)

## Model
![assets/model.jpg](assets/model.jpg)

## Prerequisites
- Python 3 (>= 3.6)
- Jupyter Notebook
- keras (2.x)
- librosa
- scipy
- Linux or MacOSX

## Credits
- Concept/Machine Learning/Music: Nao Tokui
- Machine Learning: Yuma Kajihara
- UI Design/Programming: Shoya Dozono
